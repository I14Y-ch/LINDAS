name: Weekly Concept2Lindas Update

on:
  schedule:
    - cron: '0 0 * * 1'  # Runs at 00:00 every Monday
  workflow_dispatch:

env:
  PYTHON_VERSION: '3.10'
  STARDOG_URL: 'https://stardog-test.cluster.ldbar.ch/lindas'
  TARGET_GRAPH: 'https://lindas.admin.ch/fso/i14y'
  BATCH_SIZE: 30

jobs:
  get-concepts:
    runs-on: ubuntu-latest
    outputs:
      concept_ids: ${{ steps.get-concepts.outputs.concept_ids }}
      total_batches: ${{ steps.calculate-batches.outputs.total_batches }}
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install rdflib requests

    - name: Get all concept IDs
      id: get-concepts
      run: |
        python -c "
        from src.versioning.utils import get_all_concepts
        from src.versioning.config import STATUSES
        concepts = get_all_concepts(STATUSES)
        concept_ids = [c['id'] for c in concepts]
        print('Total concepts found:', len(concept_ids))
        print('::set-output name=concept_ids::' + ','.join(concept_ids))
        "

    - name: Calculate total batches needed
      id: calculate-batches
      run: |
        CONCEPT_IDS='${{ steps.get-concepts.outputs.concept_ids }}'
        IFS=',' read -ra ID_ARRAY <<< "$CONCEPT_IDS"
        TOTAL_CONCEPTS=${#ID_ARRAY[@]}
        BATCH_SIZE=${{ env.BATCH_SIZE }}
        TOTAL_BATCHES=$(( (TOTAL_CONCEPTS + BATCH_SIZE - 1) / BATCH_SIZE ))
        echo "Total concepts: $TOTAL_CONCEPTS"
        echo "Total batches needed: $TOTAL_BATCHES"
        echo "::set-output name=total_batches::$TOTAL_BATCHES"

  process-batches-sequential:
    needs: get-concepts
    runs-on: ubuntu-latest
    timeout-minutes: 240  # Increase timeout for sequential processing
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install rdflib requests

    - name: Process all batches sequentially
      env:
        CONCEPT_IDS: ${{ needs.get-concepts.outputs.concept_ids }}
        TOTAL_BATCHES: ${{ needs.get-concepts.outputs.total_batches }}
      run: |
        for ((batch_index=0; batch_index<$TOTAL_BATCHES; batch_index++)); do
          echo "Processing batch $batch_index"
          python src/main.py --batch-index $batch_index --batch-size ${{ env.BATCH_SIZE }}
        done

    - name: Upload all batch outputs
      uses: actions/upload-artifact@v4
      with:
        name: all-batches
        path: |
          batch_*_output.ttl
          output.ttl

  combine-results:
    needs: process-batches-sequential
    runs-on: ubuntu-latest
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Download all batch artifacts
      uses: actions/download-artifact@v4
      with:
        path: batches/
        pattern: all-batches
        merge-multiple: true

    - name: Combine all RDF files
      run: |
        # Combine all batch files
        cat batches/batch_*_output.ttl batches/output.ttl 2>/dev/null | grep -v "^@prefix" > combined_temp.ttl
        
        # Add prefixes from first file
        head -n 20 batches/output.ttl | grep "^@prefix" > final_output.ttl
        echo "" >> final_output.ttl
        cat combined_temp.ttl >> final_output.ttl
        rm combined_temp.ttl
        
        echo "Combined RDF file created"

    - name: Validate combined RDF
      run: |
        python -c "
        from rdflib import Graph
        g = Graph()
        g.parse('final_output.ttl', format='turtle')
        print(f'Validated combined RDF with {len(g)} triples')
        "

    - name: Get OUTPUT_FILE_NAME from Python config
      id: get-output-filename
      run: |
        OUTPUT_FILE=$(python -c "from src.versioning.config import OUTPUT_FILE_NAME; print(OUTPUT_FILE_NAME)")
        echo "OUTPUT_FILE=$OUTPUT_FILE" >> $GITHUB_ENV

    - name: Clear Stardog Graph
      env:
        STARDOG_USER: ${{ secrets.STARDOG_USER }}
        STARDOG_PASSWORD: ${{ secrets.STARDOG_PASSWORD_TEST }}
      run: |
        python -c "
        from requests import post
        from requests.auth import HTTPBasicAuth
        auth = HTTPBasicAuth('$STARDOG_USER', '$STARDOG_PASSWORD')
        response = post(
            '$STARDOG_URL/update',
            headers={'Content-Type': 'application/sparql-update'},
            auth=auth,
            data='CLEAR GRAPH <$TARGET_GRAPH>',
            verify=False
        )
        response.raise_for_status()
        print('Graph cleared')
        "

    - name: Upload to Stardog
      env:
        STARDOG_USER: ${{ secrets.STARDOG_USER }}
        STARDOG_PASSWORD: ${{ secrets.STARDOG_PASSWORD_TEST }}
      run: |
        python -c "
        from requests import post
        from requests.auth import HTTPBasicAuth
        with open('final_output.ttl', 'rb') as f:
            response = post(
                '$STARDOG_URL',
                params={'graph': '$TARGET_GRAPH'},
                headers={'Content-Type': 'text/turtle'},
                auth=HTTPBasicAuth('$STARDOG_USER', '$STARDOG_PASSWORD'),
                data=f,
                verify=False
            )
        response.raise_for_status()
        print('Upload successful')
        "

    - name: Archive final results
      uses: actions/upload-artifact@v4
      with:
        name: final-codelist-catalog
        path: final_output.ttl
