name: Weekly Concept2Lindas Update

on:
  schedule:
    - cron: '0 0 * * 1'  # 00:00 every Monday
  workflow_dispatch:

env:
  PYTHON_VERSION: '3.10'
  STARDOG_URL: 'https://stardog-test.cluster.ldbar.ch/lindas'
  TARGET_GRAPH: 'https://lindas.admin.ch/fso/i14y'
  BATCH_SIZE: '30'  # strings in env; cast to int in code

jobs:
  get-concepts:
    runs-on: ubuntu-latest
    outputs:
      concept_ids: ${{ steps.get-concepts.outputs.concept_ids }}
      total_concepts: ${{ steps.get-concepts.outputs.total_concepts }}
      batch_matrix: ${{ steps.get-concepts.outputs.batch_matrix }}
      output_file: ${{ steps.get-output-filename.outputs.filename }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install rdflib requests

      - name: Get OUTPUT_FILE_NAME from Python config
        id: get-output-filename
        run: |
          OUTPUT_FILE=$(python -c "from concept2sharedDimension.src.versioning.config import OUTPUT_FILE_NAME; print(OUTPUT_FILE_NAME)")
          echo "filename=$OUTPUT_FILE" >> $GITHUB_OUTPUT

      - name: Get all concept IDs + build matrix
        id: get-concepts
        shell: bash
        run: |
          python - <<'PY'
          import json, os
          from concept2sharedDimension.src.versioning.utils import get_all_concepts
          from concept2sharedDimension.src.versioning.config import STATUSES

          concepts = get_all_concepts(STATUSES)
          ids = [c['id'] for c in concepts]
          print(f"Total concepts found: {len(ids)}")

          batch_size = int(os.environ.get('BATCH_SIZE','30'))
          n_batches = (len(ids) + batch_size - 1) // batch_size
          print(f"Will create {n_batches} batches of size {batch_size}")
          
          # Run at least one empty batch so downstream jobs execute cleanly.
          matrix = {"include": [{"batch_index": i} for i in range(max(1, n_batches))]}

          with open(os.environ['GITHUB_OUTPUT'], 'a') as gh:
            print(f"concept_ids={','.join(ids)}", file=gh)
            print(f"total_concepts={len(ids)}", file=gh)
            print(f"batch_matrix={json.dumps(matrix)}", file=gh)
          PY

      - name: Clear Stardog Graph (once before all batches)
        env:
          STARDOG_USER: ${{ secrets.STARDOG_USER }}
          STARDOG_PASSWORD: ${{ secrets.STARDOG_PASSWORD_TEST }}
        run: |
          python -c "
          import os, warnings, requests
          warnings.filterwarnings('ignore')
          from requests.auth import HTTPBasicAuth
          auth = HTTPBasicAuth(os.environ['STARDOG_USER'], os.environ['STARDOG_PASSWORD'])
          url = os.environ['STARDOG_URL'].rstrip('/') + '/update'
          target = os.environ['TARGET_GRAPH']
          r = requests.post(
              url,
              headers={'Content-Type': 'application/sparql-update'},
              auth=auth,
              data=f'CLEAR GRAPH <{target}>',
              verify=False
          )
          r.raise_for_status()
          print('âœ“ Graph cleared successfully - ready for batch uploads')
          "

  process-and-upload-batches:
    needs: get-concepts
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix: ${{ fromJSON(needs.get-concepts.outputs.batch_matrix) }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install rdflib requests

      - name: Calculate batch range
        id: calc-batch
        shell: bash
        run: |
          CONCEPT_IDS='${{ needs.get-concepts.outputs.concept_ids }}'
          BATCH_SIZE=${{ env.BATCH_SIZE }}
          BATCH_INDEX=${{ matrix.batch_index }}

          # Convert comma-separated string to array
          IFS=',' read -ra ID_ARRAY <<< "$CONCEPT_IDS"
          TOTAL_IDS=${#ID_ARRAY[@]}

          echo "Total concept IDs: $TOTAL_IDS"
          echo "Batch size: $BATCH_SIZE" 
          echo "Batch index: $BATCH_INDEX"

          START=$((BATCH_INDEX * BATCH_SIZE))
          END=$((START + BATCH_SIZE))

          echo "Calculated range: $START to $END"

          # Handle case where END exceeds array size
          if [ $END -gt $TOTAL_IDS ]; then
            END=$TOTAL_IDS
          fi

          BATCH_IDS=""
          for ((i=START; i<END && i<TOTAL_IDS; i++)); do
            if [ -n "$BATCH_IDS" ]; then
              BATCH_IDS="$BATCH_IDS,${ID_ARRAY[i]}"
            else
              BATCH_IDS="${ID_ARRAY[i]}"
            fi
          done

          echo "Batch IDs for batch $BATCH_INDEX: $BATCH_IDS"
          echo "Processing concepts from index $START to $((END-1))"

          {
            echo "batch_ids=$BATCH_IDS"
            echo "batch_start=$START"
            echo "batch_end=$END"
            echo "actual_batch_size=$(echo "$BATCH_IDS" | tr ',' '\n' | wc -l)"
          } >> "$GITHUB_OUTPUT"

      - name: Process batch ${{ matrix.batch_index }} (${{ steps.calc-batch.outputs.batch_start }}-${{ steps.calc-batch.outputs.batch_end }})
        if: steps.calc-batch.outputs.batch_ids != ''
        env:
          BATCH_CONCEPT_IDS: ${{ steps.calc-batch.outputs.batch_ids }}
          OUTPUT_FILE: batch_${{ matrix.batch_index }}_${{ needs.get-concepts.outputs.output_file }}
        shell: bash
        run: |
          echo "Processing batch ${{ matrix.batch_index }}"
          echo "Concept IDs: $BATCH_CONCEPT_IDS"
          echo "Batch size: ${{ steps.calc-batch.outputs.actual_batch_size }}"
          echo "Output file: $OUTPUT_FILE"
          
          # Run the main script with the environment variable set
          python -m concept2sharedDimension.src.main --batch-index ${{ matrix.batch_index }}

      - name: Validate RDF
        if: steps.calc-batch.outputs.batch_ids != ''
        env:
          OUTPUT_FILE: batch_${{ matrix.batch_index }}_${{ needs.get-concepts.outputs.output_file }}
        run: |
          python -c "
          from rdflib import Graph
          g = Graph()
          g.parse('$OUTPUT_FILE', format='turtle')
          print(f'Validated RDF with {len(g)} triples')
          "

      - name: Upload batch to Stardog
        if: steps.calc-batch.outputs.batch_ids != ''
        env:
          STARDOG_USER: ${{ secrets.STARDOG_USER }}
          STARDOG_PASSWORD: ${{ secrets.STARDOG_PASSWORD_TEST }}
          OUTPUT_FILE: batch_${{ matrix.batch_index }}_${{ needs.get-concepts.outputs.output_file }}
        run: |
          echo "Uploading batch ${{ matrix.batch_index }} to Stardog..."
          python -c "
          import os, warnings, requests
          warnings.filterwarnings('ignore')
          from requests.auth import HTTPBasicAuth
          
          output_file = os.environ['OUTPUT_FILE']
          
          # Check if file exists and has content
          if not os.path.exists(output_file) or os.path.getsize(output_file) == 0:
              print(f'Skipping upload - {output_file} is empty or does not exist')
              exit(0)
          
          auth = HTTPBasicAuth(os.environ['STARDOG_USER'], os.environ['STARDOG_PASSWORD'])
          url = os.environ['STARDOG_URL']
          params = {'graph': os.environ['TARGET_GRAPH']}
          
          with open(output_file, 'rb') as f:
              r = requests.post(
                  url, 
                  params=params, 
                  headers={'Content-Type': 'text/turtle'}, 
                  auth=auth, 
                  data=f, 
                  verify=False
              )
              r.raise_for_status()
              print(f'Successfully uploaded batch ${{ matrix.batch_index }} to Stardog')
          "

      - name: Archive batch results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: batch-${{ matrix.batch_index }}-output
          path: batch_${{ matrix.batch_index }}_${{ needs.get-concepts.outputs.output_file }}
          if-no-files-found: warn

  final-summary:
    needs: [get-concepts, process-and-upload-batches]
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Summary
        run: |
          echo "Processing Summary:"
          echo "Total concepts: ${{ needs.get-concepts.outputs.total_concepts }}"
          echo "Batch size: ${{ env.BATCH_SIZE }}"
          echo "All batches have been processed and uploaded individually to Stardog"
          echo "Target graph: ${{ env.TARGET_GRAPH }}"
